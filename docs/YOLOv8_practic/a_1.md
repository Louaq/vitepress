---
title: è¿›é˜¶å®æˆ˜â€”â€”1
top: 2
sticky: 600
---


![](https://i-blog.csdnimg.cn/blog_migrate/de1343167d4c07efe596aa131d47f5e8.png)

## ä¸€ã€æœ¬æ–‡ä»‹ç»

æœ¬æ–‡ç»™å¤§å®¶å¸¦æ¥çš„æ˜¯è¿›é˜¶å®æˆ˜ç¯‡ï¼Œåˆ©ç”¨è¾…åŠ©è¶…æ¨ç†ç®—æ³•SAHIè¿›è¡Œæ¨ç†ï¼ŒåŒæ—¶å®˜æ–¹æä¾›çš„ç‰ˆæœ¬ä¸­æ”¯æŒè§†é¢‘ï¼Œæˆ‘å°†å…¶è¿›è¡Œæ”¹é€ åä¸ä»…æ”¯æŒè§†é¢‘åŒæ—¶æ”¯æŒå›¾ç‰‡çš„æ¨ç†æ–¹å¼ï¼ŒSAHI[ä¸»è¦çš„](https://so.csdn.net/so/search?q=%E4%B8%BB%E8%A6%81%E7%9A%84&spm=1001.2101.3001.7020)æ¨ç†åœºæ™¯æ˜¯é’ˆå¯¹äºå°ç›®æ ‡æ£€æµ‹ï¼ˆæ£€æµ‹ç‰©ä½“è¾ƒå¤§çš„ä¸é€‚ç”¨ï¼Œå› ä¸ºä¼šå°†ä¸€äº›å¤§çš„ç‰©ä½“åˆ‡å‰²å¼€æ¥ä»è€Œå¯¼è‡´è¯¯æ£€ï¼‰ï¼Œæ£€æµ‹æ•ˆæœéå¸¸çš„å¥½å¯¹äºå°ç›®æ ‡æ£€æµ‹ï¼Œå°¤å…¶æ˜¯æ— äººæœºèˆªæ‹çš„å›¾ç‰‡æ£€æµ‹æˆ–è€…è¿œè·ç¦»æ‹æ‘„çš„å›¾ç‰‡ï¼Œæœ¬æ–‡ä¸­é™„ä»£ç +è¯¦ç»†çš„å‚æ•°è®²è§£å¹¶æœ‰æ•™ç¨‹ç¤ºä¾‹ï¼

![](https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/4c0b16ba1bbd680a35e3d387d8d5eb91.gif)





## äºŒã€è®ºæ–‡çš„æå‡º

![](https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/de1343167d4c07efe596aa131d47f5e8.png)

**è®ºæ–‡é“¾æ¥ï¼š**Â [å®˜æ–¹è®ºæ–‡åœ°å€ç‚¹å‡»å³å¯è·³è½¬](https://arxiv.org/pdf/2202.06934.pdf "å®˜æ–¹è®ºæ–‡åœ°å€ç‚¹å‡»å³å¯è·³è½¬")Â 

**é¡¹ç›®åœ°å€ï¼šÂ [å®˜æ–¹çš„é¡¹ç›®åœ°å€ï¼Œä½†æ˜¯æœ¬æ–‡çš„å†…å®¹å€Ÿé‰´çš„æ˜¯YOLOv8å®˜æ–¹çš„å¹¶ä¸æ˜¯æ­¤å¤„çš„ã€‚](https://github.com/obss/sahi "å®˜æ–¹çš„é¡¹ç›®åœ°å€ï¼Œä½†æ˜¯æœ¬æ–‡çš„å†…å®¹å€Ÿé‰´çš„æ˜¯YOLOv8å®˜æ–¹çš„å¹¶ä¸æ˜¯æ­¤å¤„çš„ã€‚")**

**æ‘˜è¦ï¼š**åœ¨ç›‘è§†åº”ç”¨ä¸­ï¼Œæ£€æµ‹åœºæ™¯ä¸­çš„å°ç‰©ä½“å’Œè¿œå¤„çš„ç‰©ä½“æ˜¯ä¸€ä¸ªä¸»è¦æŒ‘æˆ˜ã€‚è¿™äº›ç‰©ä½“åœ¨å›¾åƒä¸­ç”±å°‘é‡åƒç´ è¡¨ç¤ºï¼Œç¼ºä¹è¶³å¤Ÿçš„ç»†èŠ‚ï¼Œä½¿å®ƒä»¬éš¾ä»¥ä½¿ç”¨ä¼ ç»Ÿæ£€æµ‹å™¨æ£€æµ‹åˆ°ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæå‡ºäº†ä¸€ç§åä¸º"Slicing Aided Hyper Inferenceï¼ˆSAHIï¼‰"çš„å¼€æºæ¡†æ¶ï¼Œè¯¥æ¡†æ¶æä¾›äº†ä¸€ç§é€šç”¨çš„åˆ‡ç‰‡è¾…åŠ©æ¨ç†å’Œå¾®è°ƒæµç¨‹ï¼Œç”¨äºå°ç‰©ä½“æ£€æµ‹ã€‚æ‰€æå‡ºçš„æŠ€æœ¯æ˜¯é€šç”¨çš„ï¼Œå› ä¸ºå®ƒå¯ä»¥åº”ç”¨åœ¨ä»»ä½•ç°æœ‰çš„ç›®æ ‡æ£€æµ‹å™¨ä¹‹ä¸Šï¼Œæ— éœ€è¿›è¡Œä»»ä½•å¾®è°ƒã€‚å®éªŒè¯æ˜ï¼Œåœ¨Visdroneå’ŒxViewèˆªæ‹ç›®æ ‡æ£€æµ‹æ•°æ®é›†ä¸Šä½¿ç”¨ç›®æ ‡æ£€æµ‹åŸºçº¿ï¼Œæ‰€æå‡ºçš„æ¨ç†æ–¹æ³•å¯ä»¥åˆ†åˆ«å°†FCOSã€VFNetå’ŒTOODæ£€æµ‹å™¨çš„ç›®æ ‡æ£€æµ‹APæé«˜6.8%ã€5.1%å’Œ5.3%ã€‚æ­¤å¤–ï¼Œé€šè¿‡åˆ‡ç‰‡è¾…åŠ©å¾®è°ƒï¼Œæ£€æµ‹å‡†ç¡®æ€§å¯ä»¥è¿›ä¸€æ­¥æé«˜ï¼Œåˆ†åˆ«åœ¨ç›¸åŒé¡ºåºä¸Šç´¯ç§¯æé«˜12.7%ã€13.4%å’Œ14.5%çš„APã€‚æ‰€æå‡ºçš„æŠ€æœ¯å·²ä¸Detectron2ã€MMDetectionå’ŒYOLOv5æ¨¡å‹é›†æˆã€‚

* * *

## ä¸‰ã€é¡¹ç›®å®Œæ•´ä»£ç 

å¸®æˆ‘ä»¬å°†è¿™ä¸ªä»£ç ï¼Œå¤åˆ¶ç²˜è´´åˆ°æˆ‘ä»¬YOLOv8çš„ä»“åº“é‡Œç„¶ååˆ›å»ºä¸€ä¸ªpyæ–‡ä»¶å­˜æ”¾è¿›å»å³å¯ã€‚

```python
# Ultralytics YOLO ğŸš€, AGPL-3.0 license
import os
os.getcwd()
import argparse
from pathlib import Path
import cv2
from sahi import AutoDetectionModel
from sahi.predict import get_sliced_prediction
from sahi.utils.yolov8 import download_yolov8s_model
from ultralytics.utils.files import increment_path
 
 
def run(weights="yolov8n.pt", source="test.mp4", view_img=False, save_img=False, exist_ok=False):
    """
    Run object detection on a video using YOLOv8 and SAHI.
    Args:
        weights (str): Model weights path.
        source (str): Video file path.
        view_img (bool): Show results.
        save_img (bool): Save results.
        exist_ok (bool): Overwrite existing files.
    """
 
    # Check source path
    if not Path(source).exists():
        raise FileNotFoundError(f"Source path '{source}' does not exist.")
 
    yolov8_model_path = f"{weights}"
    download_yolov8s_model(yolov8_model_path)
    detection_model = AutoDetectionModel.from_pretrained(
        model_type="yolov8", model_path=yolov8_model_path, confidence_threshold=0.6, device="cpu"
    )
    if source[-3:] == 'mp4':
        # Video setup
        videocapture = cv2.VideoCapture(source)
        frame_width, frame_height = int(videocapture.get(3)), int(videocapture.get(4))
        fps, fourcc = int(videocapture.get(5)), cv2.VideoWriter_fourcc(*"mp4v")
 
        # Output setup
        save_dir = increment_path(Path("ultralytics_results_with_sahi") / "exp", exist_ok)
        save_dir.mkdir(parents=True, exist_ok=True)
        video_writer = cv2.VideoWriter(str(save_dir / f"{Path(source).stem}.mp4"), fourcc, fps, (frame_width, frame_height))
 
        while videocapture.isOpened():
            success, frame = videocapture.read()
            if not success:
                break
 
            results = get_sliced_prediction(
                frame, detection_model, slice_height=256, slice_width=256, overlap_height_ratio=0.2, overlap_width_ratio=0.2
            )
            object_prediction_list = results.object_prediction_list
 
            boxes_list = []
            clss_list = []
            for ind, _ in enumerate(object_prediction_list):
                boxes = (
                    object_prediction_list[ind].bbox.minx,
                    object_prediction_list[ind].bbox.miny,
                    object_prediction_list[ind].bbox.maxx,
                    object_prediction_list[ind].bbox.maxy,
                )
                clss = object_prediction_list[ind].category.name
                boxes_list.append(boxes)
                clss_list.append(clss)
 
            for box, cls in zip(boxes_list, clss_list):
                x1, y1, x2, y2 = box
                cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (56, 56, 255), 2)
                label = str(cls)
                t_size = cv2.getTextSize(label, 0, fontScale=0.6, thickness=1)[0]
                cv2.rectangle(
                    frame, (int(x1), int(y1) - t_size[1] - 3), (int(x1) + t_size[0], int(y1) + 3), (56, 56, 255), -1
                )
                cv2.putText(
                    frame, label, (int(x1), int(y1) - 2), 0, 0.6, [255, 255, 255], thickness=1, lineType=cv2.LINE_AA
                )
 
            if view_img:
                cv2.imshow(Path(source).stem, frame)
            if save_img:
                video_writer.write(frame)
 
            if cv2.waitKey(1) & 0xFF == ord("q"):
                break
        video_writer.release()
        videocapture.release()
        cv2.destroyAllWindows()
    else:
        results = get_sliced_prediction(
            source, detection_model, slice_height=256, slice_width=256, overlap_height_ratio=0.2, overlap_width_ratio=0.2
        )
        # ä¿å­˜æ£€æµ‹å›¾ç‰‡
        results.export_visuals(export_dir="demo_data/")
 
 
        image = cv2.imread('demo_data/prediction_visual.png')
 
        # æ£€æŸ¥æ˜¯å¦æˆåŠŸè¯»å–å›¾ç‰‡
        if image is not None:
            # æ˜¾ç¤ºå›¾ç‰‡
            cv2.imshow('PNG Image', image)
 
            # ç­‰å¾…æŒ‰é”®è¾“å…¥ï¼Œå¹¶å…³é—­çª—å£
            cv2.waitKey(0)
            cv2.destroyAllWindows()
        else:
            print("Failed to read PNG image.")
def parse_opt():
    """Parse command line arguments."""
    parser = argparse.ArgumentParser()
    parser.add_argument("--weights", type=str, default="yolov8n.pt", help="initial weights path")
    parser.add_argument("--source", type=str, default='ultralytics/assets/bus.jpg', help="video file path or Photo")
    parser.add_argument("--view-img", action="store_true", default=True, help="show results")
    parser.add_argument("--save-img", action="store_true", help="save results")
    parser.add_argument("--exist-ok", action="store_true", help="existing project/name ok, do not increment")
    return parser.parse_args()
 
 
def main(opt):
    """Main function."""
    run(**vars(opt))
 

if __name__ == "__main__":
    opt = parse_opt()
    main(opt)
```

## å››ã€å‚æ•°è§£æÂ 

ä¸‹é¢ä¸Šé¢é¡¹ç›®æ ¸å¿ƒä»£ç çš„å‚æ•°è§£æï¼Œå…±æœ‰10ä¸ªï¼Œèƒ½å¤Ÿèµ·åˆ°ä½œç”¨çš„å‚æ•°å¹¶ä¸å¤šã€‚Â 

|  | å‚æ•°å | å‚æ•°ç±»å‹ | å‚æ•°è®²è§£ |
| --- | --- | --- | --- |
| 0 | weights | Â str | ç”¨äºæ£€æµ‹è§†é¢‘çš„æƒé‡æ–‡ä»¶åœ°å€ï¼ˆå¯ä»¥æ˜¯ä½ è®­ç»ƒå¥½çš„ï¼Œä¹Ÿå¯ä»¥æ˜¯å®˜æ–¹æä¾›çš„ï¼‰ |
| 1 | source | str | è§†é¢‘æ–‡ä»¶çš„åœ°å€æˆ–è€…å›¾ç‰‡çš„åœ°å€ï¼Œå®˜æ–¹æœ¬èº«åªæ”¯æŒå›¾ç‰‡ï¼Œæˆ‘è¿™é‡ŒåŠ äº†ç‚¹å¤„ç†ä»è€Œæ”¯æŒå›¾ç‰‡çš„æ£€æµ‹ï¼Œåªéœ€è¦è¾“å…¥åœ°å€å³å¯æ¨¡å‹ä¼šè‡ªåŠ¨è¿›è¡Œåˆ¤æ–­ã€‚ |
| 2 | view-img | bool | Â æ˜¯å¦æ˜¾ç¤ºè§†é¢‘ç»“æœ ï¼Œå°±æ˜¯å®ƒåœ¨æ§åˆ¶å°ä¼šè¾“å‡ºç»“æœï¼Œå¦‚æœè®¾ç½®ä¸ºTrueå°±æ˜¾ç¤ºå›¾åƒç»“æœ |
| 3 | save-img | bool | æ˜¯å¦ä¿å­˜æ£€æµ‹çš„ç»“æœï¼Œæ–‡ä»¶ä¼šå­˜æ”¾åœ¨åŒçº§ç›®å½•ä¸‹çš„æ–°æ–‡ä»¶å¤¹å†… |
| 4 | exist-ok | bool | ä¿å­˜æ–‡ä»¶çš„åå­—æ£€æµ‹çš„ï¼Œå¤§å®¶ä¸ç”¨ç†ä¼šè¿™ä¸ªå‚æ•° |

## äº”ã€é¡¹ç›®çš„ä½¿ç”¨æ•™ç¨‹

### 5.1 æ­¥éª¤ä¸€

æˆ‘ä»¬åœ¨Yoloä»“åº“çš„ç›®å½•ä¸‹åˆ›å»ºä¸€ä¸ªpyæ–‡ä»¶å°†ä»£ç å­˜æ”¾è¿›å»ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚

![](https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/ddc73374efdf12376cafd68e5167fb2e.png)

* * *

### 5.2 æ­¥éª¤äºŒ

**æˆ‘ä»¬æŒ‰ç…§å‚æ•°è§£æéƒ¨åˆ†çš„ä»‹ç»å¡«å¥½å¤§å®¶çš„å‚æ•°ï¼Œä¸»è¦é…ç½®çš„æœ‰ä¸¤ä¸ªä¸€ä¸ªå°±æ˜¯æƒé‡æ–‡ä»¶åœ°å€å¦ä¸€ä¸ªå°±æ˜¯è§†é¢‘æˆ–è€…å›¾ç‰‡çš„åœ°å€ã€‚**

![](https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/75d503dbd5c5734cf8386d65b30923ee.png)

* * *

### 5.3 æ­¥éª¤ä¸‰

æˆ‘ä»¬å¡«å†™ä¹‹åè¿è¡Œæ–‡ä»¶å³å¯ï¼Œæ­¤æ—¶ä¼šå¼¹å‡ºè§†é¢‘æ¡†æˆ–è€…å›¾ç‰‡æ£€æµ‹æ¡†ã€‚

![](https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/5415fd33f7a202f6d1bd59118e1024c3.png)

* * *

### 5.4 é‡è¦çš„è¶…å‚æ•°ï¼Â 

è¿˜æœ‰ä¸€ä¸ªç½®ä¿¡åº¦çš„è¶…å‚æ•°æ¯”è¾ƒé‡è¦ï¼Œå¤§å®¶å¯ä»¥æ ¹æ®è‡ªå·±çš„éœ€æ±‚å¡«å†™ã€‚

![](https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/76b46b97f613ea0eb0177a33e906d350.png)

